{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# STORY TITLING USING NLP"
      ],
      "metadata": {
        "id": "ysmslJ-E5t4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mounting Drive**"
      ],
      "metadata": {
        "id": "o2t7_9435kZ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGJ0AGLNTvy8",
        "outputId": "e1069558-0368-4fa8-8128-9425b733142a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "Z3EXWP4F58p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "R0leuAFFT1KC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Dataset**"
      ],
      "metadata": {
        "id": "il10mLwX6BJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('/content/drive/MyDrive/storydataset.xlsx')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "r3PTW8NBT3g-",
        "outputId": "62d60f43-0124-4c78-eee1-9bea1c39f451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   S.NO                                              STORY  \\\n",
              "0     1  Once, there was a boy who became bored when he...   \n",
              "1     2  There once was a king named Midas who did a go...   \n",
              "2     3  One day, a fox became very hungry as he went t...   \n",
              "3     4  Once upon a time, in a desert far away, there ...   \n",
              "4     5  One day, Molly the milkmaid had filled her pai...   \n",
              "\n",
              "                  STORY NAME  \n",
              "0     The Boy Who Cried Wolf  \n",
              "1           The Golden Touch  \n",
              "2    The Fox and  the Grapes  \n",
              "3             The Proud Rose  \n",
              "4  The Milkmaid and Her Pail  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89b4a7bb-b3ee-4c5e-8838-6770fafc9689\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S.NO</th>\n",
              "      <th>STORY</th>\n",
              "      <th>STORY NAME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Once, there was a boy who became bored when he...</td>\n",
              "      <td>The Boy Who Cried Wolf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>There once was a king named Midas who did a go...</td>\n",
              "      <td>The Golden Touch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>One day, a fox became very hungry as he went t...</td>\n",
              "      <td>The Fox and  the Grapes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Once upon a time, in a desert far away, there ...</td>\n",
              "      <td>The Proud Rose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>One day, Molly the milkmaid had filled her pai...</td>\n",
              "      <td>The Milkmaid and Her Pail</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89b4a7bb-b3ee-4c5e-8838-6770fafc9689')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89b4a7bb-b3ee-4c5e-8838-6770fafc9689 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89b4a7bb-b3ee-4c5e-8838-6770fafc9689');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data PreProcessing**"
      ],
      "metadata": {
        "id": "eJaP3uQJ6G01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop([\"S.NO\"],axis = 1)"
      ],
      "metadata": {
        "id": "1d6c8Ss7T_yE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = data['STORY']\n",
        "y = data['STORY NAME']"
      ],
      "metadata": {
        "id": "9LqqQl6AUD8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_cleaner(text):\n",
        "    newString = text.lower()\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)   \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
        "    newString = re.sub(\"  \",\" \",newString)\n",
        "    return newString"
      ],
      "metadata": {
        "id": "vUjXHOYuKjF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_x = []\n",
        "for t in x:\n",
        "    cleaned_x.append(text_cleaner(t))\n",
        "cleaned_x[0]  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "9vq6rEsQKo6g",
        "outputId": "2bf11bd9-0b6f-4d80-8430-3f49623d43ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'once there was a boy who became bored when he watched over the village sheep grazing on the hillside to entertain himself he sang out  wolf wolf the wolf is chasing the sheep when the villagers heard the cry they came running up the hill to drive the wolf away but when they arrived they saw no wolf the boy was amused when seeing their angry faces don t scream wolf boy  warned the villagers  when there is no wolf  they angrily went back down the hill later the shepherd boy cried out once again  wolf wolf the wolf is chasing the sheep  to his amusement he looked on as the villagers came running up the hill to scare the wolf away as they saw there was no wolf they said strictly  save your frightened cry for when there really is a wolf don t cry wolf when there is no wolf  but the boy grinned at their words while they walked grumbling down the hill once more later the boy saw a real wolf sneaking around his flock alarmed he jumped on his feet and cried out as loud as he could  wolf wolf  but the villagers thought he was fooling them again and so they didn t come to help at sunset the villagers went looking for the boy who hadn t returned with their sheep when they went up the hill they found him weeping there really was a wolf here the flock is gone i cried out  wolf  but you didn t come  he wailed an old man went to comfort the boy as he put his arm around him he said  nobody believes a liar even when he is telling the truth '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_y = []\n",
        "for t in y:\n",
        "    cleaned_y.append(text_cleaner(t))\n",
        "cleaned_y[0] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MOAfq5dYKr5v",
        "outputId": "835428dd-3405-42c5-b8fe-a0393c9cc355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the boy who cried wolf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=cleaned_x\n",
        "y=cleaned_y"
      ],
      "metadata": {
        "id": "MW5L0fYGKwJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len_story=max(len(t) for t in x)\n",
        "max_len_title=max(len(t) for t in y)\n",
        "print(max_len_story)\n",
        "print(max_len_title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRA0rkPbK3kg",
        "outputId": "bfd3e827-f2af-4b40-8ad5-a840e11ff9d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4144\n",
            "42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "story_word_count = []\n",
        "title_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in x:\n",
        "      story_word_count.append(len(i.split()))\n",
        "\n",
        "for i in y:\n",
        "      title_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'story':story_word_count, 'title':title_word_count})\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "KQT2TGchLh-t",
        "outputId": "be9889dd-aa81-4423-8ee4-23ad9e26a674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEICAYAAACgQWTXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAaIUlEQVR4nO3dfbQd1Xnf8e8PSYAQKoKAb4XAuXLtKMuxgsAKheC6qnixAq5x1mKlaNkYxbjEbUnBVYtlu41x0iRyCybEzrItA0axMS+WwVDqF2Ssu6hTLBfJAgmEg4xlkIIkCOZFxG+Cp3+cfdBhdM6952XOOftOfp+1zrpz9sycee7cOc+d2TN7b0UEZmZWDQcNOwAzMyuPk7qZWYU4qZuZVYiTuplZhTipm5lViJO6mVmFOKmbWV9Jeq2kvZKmjLNMSHr9IOOqKif1AZJ0haQvDjsOs36TtF3SGQAR8XhEHB4RL6V5Y5LeN9wIq8tJfRKRNHXYMZhZ3pzU+0TSByXtlPSCpB9IOgf4MPBv0qXoA2m5YyXdKekZSdsk/duGz7hC0hpJX5T0PLBC0j9I+pWGZU6S9JSkaQP/Jc2akPQF4LXA/0rH+uWpemWqpD8F/gXwqTTvU03WP0TSlZIel7Rb0mckTR/07zFZOan3gaR5wCXAb0XETOBtwCPAnwG3pEvRE9LiNwM7gGOB84A/k7S44ePOBdYAs4CrgDHg9xrmXwDcHBG/7N9vZNa+iLgAeBz41xFxOHBrw7yPAP8HuCR9Dy5p8hErgV8DFgCvB+YAf9T3wCvCSb0/XgIOAd4oaVpEbI+IHxYXknQ8cBrwwYj4WURsAq4F3tOw2H0R8dWIeDkifgqsBt6d1p8CLAW+0Offx2wgJAm4GPhARDwTES9QOxk6f7iRTR5O6n0QEduAy4ArgD2SbpZ0bJNFjwXqB27dj6mdmdQ9UVjnDmr/LOYCZwLPRcT3SgvebLiOAQ4DNkh6VtKzwDdSubXBSb1PIuJLEfEW4FeBAD6efjb6O+AoSTMbyl4L7Gz8qMLn/oza5ey7qVW9+CzdcjRe96/jzXsa+CnwGxExK72OSNU41gYn9T6QNE/SYkmHAD+jdpC+DOwGRiUdBBARTwD/F/hzSYdK+k3gImCixx7/GlgGvAMndcvTbuB1nc6LiJeBzwFXS3oNgKQ5kt7WlygryEm9Pw6hdrPnaWAX8BrgQ8CX0/y/l7QxTS8FRqmdtd8OfDQivjXeh0fE31D7J7ExIn5cevRmvftz4L+m6pPzCvOuAc6T9BNJf9lk3Q8C24Dvpqe+vgXM62u0FSIPkjE5Sfo28KWIuHbYsZhZPpzUJyFJvwWsBY4v3GQ1s3/kXP0yyUhaTe1y9DIndDMr8pm6mVmF+EzdzKxCBtpB1NFHHx2jo6MD296LL77IjBkzBra9djmuzjXGtmHDhqcjYlI0Rhn0MQ95/h1ziym3eGD8mDo65iNiYK83v/nNMUjr1q0b6Pba5bg61xgbcH/08TgFDgW+BzwAPAR8LJXfAPwI2JReCyb6rEEf8xF5/h1ziym3eCLGj6mTY95duZod6OfA4ojYm3q//I6kr6d5/yUi1gwxNrNxOambFaQzo73p7bT08hMFNin4RqlZE5KmSNoE7AHWRsT6NOtPJT0o6erUDYRZVnymbtZE1IZeWyBpFnC7pDdR6+phF3AwsIpac/Y/Lq4r6WJq3ccyMjLC2NjYoMIGYO/evQPf5kRyiym3eKC8mJzUzcYREc9KWgcsiYgrU/HPJX0e+M8t1llFLemzcOHCWLRo0UBirRsbG2PQ25xIbjHlFg+UF5OrX8wKJB2TztBJw6idCTwiaXYqE/BOYMvwojRrzmfqZgeaDaxOI0sdBNwaEXdJ+rakYwBRe6Tx/cMM0qwZJ3Wzgoh4EDixSfniJoubZcXVL2ZmFTJpztRHV/zvA8q2rzxnCJGYWbvq39vl8/exLE37e9tfPlM3M6sQJ3UzswpxUjczqxAndTOzCnFSNzOrECd1M7MKcVI3M6sQJ3UzswpxUjczq5AJk7qk6yXtkXRAj3SSlksKSUf3JzwzM+tEO2fqNwBLioWSjgfOAh4vOSYzM+vShEk9Iu4Fnmky62rgcjx2o5lZNrqqU5d0LrAzIh4oOR4zM+tBx700SjoM+DC1qpd2li9lvMbl8/cdUDbRZ+U4DiE4rm7kHJtZTrrpevefAXOBB2qjenEcsFHSyRGxq7hwWeM1LmvW9e67xv+sHMchBMfVjZxjM8tJx0k9IjYDr6m/l7QdWBgRT5cYl5mZdaGdRxpvAu4D5knaIemi/odlZmbdmPBMPSKWTjB/tLRozMysJ25RamZWIU7qZmYV4qRuViDpUEnfk/SApIckfSyVz5W0XtI2SbdIOnjYsZoVOambHejnwOKIOAFYACyRdArwceDqiHg98BPADw1YdpzUzQqiZm96Oy29AlgMrEnlq4F3DiE8s3F10/jIrPIkTQE2AK8H/gr4IfBsRNSbNu8A5rRYt5RW1N3KqfVtvSX4yPT90znEltM+qisrJid1syYi4iVggaRZwO3Ar3ewbimtqLuVU+vbekvw5fP3cdXmWrqZqCX4IOS0j+rKisnVL2bjiIhngXXAqcAsSfUToeOAnUMLzKwFJ3WzAknHpDN0JE0HzgS2Ukvu56XFLgTuGE6EZq25+sXsQLOB1ale/SDg1oi4S9LDwM2S/jvwfeC6YQZp1oyTullBRDwInNik/DHg5MFHZNY+V7+YmVWIk7qZWYU4qZuZVYiTuplZhTipm5lViJO6mVmFOKmbmVWIk7qZWYW0M/D09ZL2SNrSUPY/JT0i6UFJt9ebVJuZ2XC1c6Z+A7CkULYWeFNE/Cbwt8CHSo7LzMy6MGFSj4h7gWcKZXc39Cv9XWo91pmZ2ZCV0ffLe4FbWs0sa8CAegf7jSb6rBw7wgfH1Y2cYzPLSU9JXdJHgH3Aja2WKWvAgHpn+40m6mw/x47wwXF1I+fYcjfa7Luz8pwhRGKD0HVSl7QMeDtwekREaRGZmVnXukrqkpYAlwP/MiL+odyQzMysW+080ngTcB8wT9IOSRcBnwJmAmslbZL0mT7HaWZmbZjwTD0iljYp9ogvZmYZcotSM7MKcVI3M6sQJ3UzswpxUjczqxAndbMCScdLWifpYUkPSbo0lV8haWd64muTpLOHHatZURndBJhVzT5geURslDQT2CBpbZp3dURcOcTYzMblpG5WEBFPAk+m6RckbQXmDDcqs/a4+sVsHJJGgROB9anokjSOwPWSjhxaYGYtTOoz9WJHRe6kyMok6XDgK8BlEfG8pE8DfwJE+nkVtV5Ki+uV0jNpt4o9WnbTw2lZ6tsemb5/OofeNnPs9bOsmCZ1UjfrF0nTqCX0GyPiNoCI2N0w/3PAXc3WLatn0m4Ve7TspofTstS3vXz+Pq7aPHWg2x5Pjr1+lhWTq1/MCiSJWlcYWyPiEw3lsxsW+11gS3Fds2HzmbrZgU4DLgA2S9qUyj4MLJW0gFr1y3bgD4YTnllrTupmBRHxHUBNZn1t0LGYdcrVL2ZmFeKkbmZWIU7qZmYV4qRuZlYhTupmZhXipG5mViHtDDx9vaQ9krY0lB0laa2kR9NP94FhZpaBds7UbwCWFMpWAPdExBuAe9J7MzMbsgmTekTcCzxTKD4XWJ2mVwPvLDkuMzPrQrctSkdSn9MAu4CRVguW1WNds57mioqfnWNPbOC4upFzbGY56bmbgIgISTHO/FJ6rGvW01xRsfe3HHtiA8fVjZxjM8tJt0+/7K73WJd+7ikvJDMz61a3Sf1O4MI0fSFwRznhmJlZL9p5pPEm4D5gnqQdki4CVgJnSnoUOCO9NzOzIZuwTj0ilraYdXrJsZiZWY/cotTMrEKc1M3MKsRJ3cysQpzUzcwqxEndzKxCnNTNzCrESd3MrEKc1M0KJB0vaZ2khyU9JOnSVO5xBCx7PXfoVZbRQodd21ee0/NnLJ+/j0V92I5V3j5geURslDQT2CBpLbCM2jgCKyWtoDaOwAeHGKfZAXymblYQEU9GxMY0/QKwFZiDxxGwSSCbM3WzHEkaBU4E1tPmOAJljSHQrWLf883GIhhUTPVtj0zfP51Dv/g59s9fVkxO6mYtSDoc+ApwWUQ8L+mVeeONI1DWGALdKvY932wsguLYA/1S3/by+fu4avPUgW57PDn2z19WTK5+MWtC0jRqCf3GiLgtFXscAcuek7pZgWqn5NcBWyPiEw2zPI6AZc/VL2YHOg24ANgsaVMq+zC1cQNuTWMK/Bj4vSHFZ9aSk7pZQUR8B1CL2R5HwLLm6hczswpxUjczq5CekrqkD6Rm1Fsk3STp0LICMzOzznWd1CXNAf4jsDAi3gRMAc4vKzAzM+tcr9UvU4HpkqYChwF/13tIZmbWra6ffomInZKuBB4HfgrcHRF3F5drt8l0sSnzJ2+8ozC/8xhHpk/8OcX5APPnHNH5xjqQYxNlyDcuyDs2s5x0ndRTt6PnAnOBZ4EvS3p3RHyxcbl2m0w3a8rcq8amyZ3odzPmHJsoQ75xQd6xmeWkl+qXM4AfRcRTEfFL4Dbgt8sJy8zMutFLUn8cOEXSYalZ9enUuig1M7Mh6TqpR8R6YA2wEdicPmtVSXGZmVkXeuomICI+Cny0pFjMzKxHblFqZlYhTupmZhXipG5mViFO6mZmFeKkbmZWIU7qZmYV4qRuZlYhTupmZhXipG5mViFO6mZmFeKkbtaEpOsl7ZG0paHsCkk7JW1Kr7OHGaNZM07qZs3dACxpUn51RCxIr68NOCazCTmpmzUREfcCzww7DrNO9dRLo9k/QpdIeg9wP7A8In5SXKDdIRz7pTj0X3GoSGBgMdW3PTJ9/3QOwxLmODxiWTE5qZu179PAnwCRfl4FvLe4ULtDOPZLcei/ZkNF9nvIxuK2G4eWHNS2x5Pj8IhlxeTqF7M2RcTuiHgpIl4GPgecPOyYzIqc1M3aJGl2w9vfBba0WtZsWFz9YtaEpJuARcDRknZQG+FrkaQF1KpftgN/MLQAzVpwUjdrIiKWNim+buCBmHWop+oXSbMkrZH0iKStkk4tKzAzM+tcr2fq1wDfiIjzJB0MHFZCTGZm1qWuk7qkI4C3AssAIuIXwC/KCcvMzLrRy5n6XOAp4POSTgA2AJdGxIuNC7XbEKNZA4leNTZ46ES/GyXk2PAB8o0L8o7NLCe9JPWpwEnAH0bEeknXACuA/9a4ULsNMZo1kOhVY4OHTvS7cUSODR8g37gg79jMctLLjdIdwI6IWJ/er6GW5M3MbEi6TuoRsQt4QtK8VHQ68HApUZmZWVd6ffrlD4Eb05MvjwG/33tIZpaj0UIV6faV5wwpEhtPT0k9IjYBC0uKxczMeuS+X8zMKsRJ3cysQpzUzcwqxEndzKxC3Euj2STiJ1BsIj5TNzOrECd1M7MKcVI3M6sQ16l3yXWbZpYjn6mbmVWIk7qZWYU4qZuZVYiTuplZhTipmzUh6XpJeyRtaSg7StJaSY+mn0cOM0azZpzUzZq7AVhSKFsB3BMRbwDuSe/NsuKkbtZERNwLPFMoPhdYnaZXA+8caFBmbfBz6mbtG4mIJ9P0LmCk2UKSLgYuBhgZGWFsbKy0AJbP3/eq980+e+/eva8qL67Tar0ytt1qnZHp+6fL3B/dKu6jHJQVk5O6WRciIiRFi3mrgFUACxcujEWLFpW23WXFRm/vOvCzx8bGaNxmcZ1W65Wx7VbrLJ+/j6s2T+1622Ur7qMclBVTz9UvkqZI+r6ku3qOxixvuyXNBkg/9ww5HrMDlFGnfimwtYTPMcvdncCFafpC4I4hxmLWVE9JXdJxwDnAteWEY5YHSTcB9wHzJO2QdBGwEjhT0qPAGem9WVZ6rVP/C+ByYGYJsZhlIyKWtph1+kADMetQ10ld0tuBPRGxQdKicZZr60mAZnfoe9V4x70TndzV72SduhzvvEO+cUHesZnlpJcz9dOAd0g6GzgU+CeSvhgR725cqN0nAZrdoe9V4x33TnRyV7+TdepyvPMO+cYFecdmlpOu69Qj4kMRcVxEjALnA98uJnQzMxsstyg1M6uQUhofRcQYMFbGZ5mZWfd8pm5mViFO6mZmFeKkbmZWIU7qZmYV4qRuZlYhTupmZhXipG5mViFO6mZmFeKRj5oYLfbrsvKcvqxjZlY2n6mbmVWIk7qZWYU4qZuZVYiTuplZhfhGqZllpfjQAfjBg074TN3MrEKc1M3MKsTVL2YdkrQdeAF4CdgXEQuHG5HZfk7qZt35VxHx9LCDMCty9YuZWYV0faYu6Xjgr4ERIIBVEXFNWYGZZSyAuyUF8NmIWNU4U9LFwMUAIyMjjI2Nlbbh5fP3vep9s8/eu3fvq8qL67Rar4xtt1pnZPr+6YnWKyve8RT3UQ7KiqmX6pd9wPKI2ChpJrBB0tqIeLjnqMzy9paI2CnpNcBaSY9ExL31mSnJrwJYuHBhLFq0qLQNLyv2MfSuAz97bGyMxm0W12m1XhnbbrXO8vn7uGrz1LbWKyve8RT3UQ7Kiqnr6peIeDIiNqbpF4CtwJyeIzLLXETsTD/3ALcDJw83IrP9SrlRKmkUOBFY32ReW5eizS65etV4ydeLT954xwFly+d3vs78OUcA+y+zNu98ruUyw5DjJWldLrFJmgEcFBEvpOmzgD8eclhmr+g5qUs6HPgKcFlEPF+c3+6laLNLrl41XvLloH4JWb/MGsRlZidyvCStyyi2EeB2SVD7/nwpIr4x3JDM9usp40maRi2h3xgRt5UTklm+IuIx4IRhx2HWStd16qqdqlwHbI2IT5QXkpmZdauX59RPAy4AFkvalF5nlxSXmZl1oevql4j4DqASYzEzsx65RamZWYU4qZuZVYiTuplZhTipm5lVSD4tc8zMhqwKQ+n5TN3MrEKc1M3MKsRJ3cysQlynPkCjDX1Lt+rArFin1019XrN6waJmn7t553OvimtQdYlVqMc0y4XP1M3MKsRn6mZDUsZVmVmRz9TNzCrESd3MrEKc1M3MKsRJ3cysQpzUzcwqxE+/mFklDerpom7bWRTXu2HJjFLi8Zm6mVmFOKmbmVVIT0ld0hJJP5C0TdKKsoIyy5mPe8tZ10ld0hTgr4DfAd4ILJX0xrICM8uRj3vLXS9n6icD2yLisYj4BXAzcG45YZlly8e9ZU0R0d2K0nnAkoh4X3p/AfDPI+KSwnIXAxent/OAH3QfbseOBp4e4Pba5bg61xjbr0bEMcMIop3jfsjHPOT5d8wtptzigfFjavuY7/sjjRGxCljV7+00I+n+iFg4jG2Px3F1LufYioZ5zEOe+yq3mHKLB8qLqZfql53A8Q3vj0tlZlXm496y1ktS/3/AGyTNlXQwcD5wZzlhmWXLx71lrevql4jYJ+kS4JvAFOD6iHiotMjKMbRL4Ak4rs5lEZuP+67lFlNu8UBJMXV9o9TMzPLjFqVmZhXipG5mViGTNqlLOl7SOkkPS3pI0qWp/ChJayU9mn4emcol6S9T0+4HJZ3U5/imSPq+pLvS+7mS1qft35JusiHpkPR+W5o/2ue4ZklaI+kRSVslnZrDPpP0gfR33CLpJkmH5rLPctTq+C8ss0jSc5I2pdcf9Tmm7ZI2p23d32T+oL+D8xp+902Snpd0WWGZvu8jSddL2iNpS0NZ0+9ck3UvTMs8KunCtjYYEZPyBcwGTkrTM4G/pdZs+38AK1L5CuDjafps4OuAgFOA9X2O7z8BXwLuSu9vBc5P058B/l2a/vfAZ9L0+cAtfY5rNfC+NH0wMGvY+wyYA/wImN6wr5blss9yfLU6/gvLLKoffwOKaTtw9DjzB/odLGx7CrCLWiOege4j4K3AScCWhrKm37nCekcBj6WfR6bpIyfc3qB26gD+aHcAZ1JrvTc7lc0GfpCmPwssbVj+leX6EMtxwD3AYuCudBA/DUxN808FvpmmvwmcmqanpuXUp7iOSMlThfKh7rOU1J9IB+/UtM/elsM+myyv+vFfKMstqQ/sO9hk22cBf9OkfCD7CBgtJPWm37nCOkuBz7baf61ek7b6pVG6/D4RWA+MRMSTadYuYCRN1xNH3Y5U1g9/AVwOvJze/wrwbETsa7LtV+JK859Ly/fDXOAp4POpauhaSTMY8j6LiJ3AlcDjwJPU9sEG8thn2Ssc/0WnSnpA0tcl/UafQwngbkkbVOsqoWiQ38Gi84GbWswb5D6qa/Wda9TV/pr0SV3S4cBXgMsi4vnGeVH79zbQZzYlvR3YExEbBrndNk2ldhn46Yg4EXiR2qXfK4a0z46k1inWXOBYYAawZJAxTFbjHf/ARmrVDScAnwS+2udw3hIRJ1HrwfI/SHprn7fXlnQv5h3Al5vMHvQ+OkDZ37lJndQlTaN2QN8YEbel4t2SZqf5s4E9qXxQzbtPA94haTu1HvwWA9cAsyTVG3s1bvuVuNL8I4C/70NcUPtPvyMi6md0a6gl+WHvszOAH0XEUxHxS+A2avsxh32WrRbH/ysi4vmI2JumvwZMk3R0v+JJV1xExB7gdmo9WjYaVhcLvwNsjIjdxRmD3kcNWn3nGnW1vyZtUpck4Dpga0R8omHWnUD9LvGF1Ooa6+XvSXfgTwGea7j8KU1EfCgijouIUWqXfN+OiHcB64DzWsRVj/e8tHxfzpQjYhfwhKR5qeh04GGGvM+oVbucIumw9HetxzX0fZarcY7/xmX+aVoOSSdT+7735Z+fpBmSZtanqdVhbyksNqjjqWgpLapeBrmPClp95xp9EzhL0pHpavasVDa+Qdyk6NONh7dQu2R5ENiUXmdTq1u9B3gU+BZwVFpe1AY3+CGwGVg4gBgXsf/pl9cB3wO2UbsMPCSVH5reb0vzX9fnmBYA96f99lVqd9WHvs+AjwGPUEsEXwAOyWWf5fga5/h/P/D+tMwlwEPAA8B3gd/uYzyvS9t5IG3zI6m8MZ5hfAdnUEvSRzSUDXQfUfuH8iTwS2pXyxeN851bCFzbsO5703G+Dfj9drbnbgLMzCpk0la/mJnZgZzUzcwqxEndzKxCnNTNzCrESd3MrEKc1M3MKsRJ3cysQv4/IGzk1Dax7X4AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting the Data**"
      ],
      "metadata": {
        "id": "ebBSFfbj6LUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
      ],
      "metadata": {
        "id": "A6_FcxFZUOt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenizing**"
      ],
      "metadata": {
        "id": "jEWJ04rW66-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WleD_GZrOV9X",
        "outputId": "f957bde5-b1fc-41c2-fcd6-038334d5d190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "JyyBO8r7OTTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoding(t):\n",
        "  enc = tokenizer.encode(t)\n",
        "  return enc"
      ],
      "metadata": {
        "id": "2cY-ZIsUOhDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#story in encoding\n",
        "x_enc=[]\n",
        "for t in x_train:\n",
        "  x_enc.append(encoding(t))\n",
        "\n",
        "print(x_enc[5])\n",
        "x_train=x_enc\n",
        "\n",
        "x2_enc=[]\n",
        "for t in x_test:\n",
        "  x2_enc.append(encoding(t))\n",
        "\n",
        "x_test=x2_enc"
      ],
      "metadata": {
        "id": "E7xBlqSyOziA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79011bec-7540-48af-dd69-70583cc82664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 1107, 170, 1353, 5118, 2077, 1210, 27031, 1296, 3489, 1108, 1104, 170, 1472, 5922, 1894, 2221, 1105, 3431, 1870, 1720, 1180, 2767, 1172, 1141, 1285, 1103, 2221, 3489, 1108, 5947, 1601, 1106, 1103, 3085, 1105, 22696, 18993, 2037, 9294, 1122, 1110, 1159, 1106, 3489, 1107, 1103, 5118, 1103, 27031, 1121, 1103, 2186, 1156, 1138, 188, 20236, 1306, 1303, 1111, 7722, 1104, 2094, 1519, 188, 1301, 5339, 4911, 1103, 4472, 2221, 3489, 18065, 1112, 1976, 1112, 1122, 1180, 1106, 1157, 1168, 1160, 2053, 5113, 5113, 178, 1198, 22696, 18993, 2037, 1152, 1132, 3693, 1106, 3963, 3489, 1107, 1142, 5118, 4911, 1195, 1538, 11231, 1106, 1103, 3429, 1104, 1103, 2186, 1111, 4911, 9294, 1115, 188, 1155, 1268, 1152, 2010, 189, 3963, 1143, 1112, 1821, 1315, 3613, 1111, 1172, 1145, 1195, 1138, 1155, 1103, 2094, 1195, 1444, 1303, 1163, 1103, 1894, 3489, 1133, 1195, 1431, 1198, 1301, 1111, 170, 1285, 1163, 1103, 2221, 3489, 178, 5340, 1114, 1103, 2221, 3489, 1142, 1110, 1313, 1133, 1195, 1444, 1106, 2215, 2914, 1163, 1103, 3431, 3489, 1152, 1793, 1106, 7627, 1147, 1910, 1133, 1175, 1108, 1185, 3219, 1103, 1397, 2106, 1103, 18993, 2641, 1147, 5795, 1105, 2347, 1112, 1242, 27031, 1112, 1152, 1180, 1199, 1127, 2448, 1199, 1127, 5925, 1199, 1127, 1653, 1199, 1127, 4321, 2528, 25090, 1174, 1105, 1621, 1172, 1108, 170, 1894, 3489, 1184, 170, 3963, 1270, 1149, 1103, 18993, 1170, 1103, 1263, 1285, 12928, 1166, 24144, 1103, 3431, 3489, 1105, 1103, 2221, 3489, 1112, 1152, 1608, 1106, 1267, 1115, 1147, 1910, 1125, 1151, 2347, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#story in encoding\n",
        "y_enc=[]\n",
        "for t in y_train:\n",
        "  y_enc.append(encoding(t))\n",
        "\n",
        "print(y_enc[5])\n",
        "y_train=y_enc\n",
        "\n",
        "y2_enc=[]\n",
        "for t in y_test:\n",
        "  y2_enc.append(encoding(t))\n",
        "\n",
        "y_test=y2_enc"
      ],
      "metadata": {
        "id": "TLXc13VCW3IL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff9a7f59-d94f-4b53-9159-a27586ece772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 1103, 8144, 1104, 1210, 27031, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "id": "6ZPENefjVltn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f23527d5-09d7-4a1d-89b0-9f3547ace4fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "#padding zero upto maximum length\n",
        "x_train    =   pad_sequences(x_train,  maxlen=max_len_story, padding='post') \n",
        "x_test   =   pad_sequences(x_test, maxlen=max_len_story, padding='post')\n",
        "\n",
        "x_voc_size   =  len(tokenizer.get_vocab()) +1"
      ],
      "metadata": {
        "id": "4nnc7GRKTqcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#padding zero upto maximum length\n",
        "y_train    =   pad_sequences(y_train, maxlen=max_len_title, padding='post')\n",
        "y_test   =   pad_sequences(y_train, maxlen=max_len_title, padding='post')\n",
        "\n",
        "y_voc_size  =   len(tokenizer.get_vocab()) +1"
      ],
      "metadata": {
        "id": "Lpt0sFFmW1ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the model**"
      ],
      "metadata": {
        "id": "nwawv4C37AfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional,Attention\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "I2DBkzokXtx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K \n",
        "K.clear_session() \n",
        "latent_dim = 15\n",
        "\n",
        "# Encoder \n",
        "encoder_inputs = Input(shape=(max_len_story,)) \n",
        "enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
        "\n",
        "#LSTM 1 \n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
        "\n",
        "#LSTM 2 \n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
        "\n",
        "#LSTM 3 \n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
        "\n",
        "# Set up the decoder. \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
        "dec_emb = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "#LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
        "\n",
        "#Attention Layer\n",
        "attention =Attention()\n",
        "attn_out = attention([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention output and decoder LSTM output \n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "model.summary()\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "QoY12rgmXeGu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cb6246c-993d-4b20-9e12-4d7b18ea5565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 4144)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 4144, 15)     434955      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 4144, 15),   1860        ['embedding[0][0]']              \n",
            "                                 (None, 15),                                                      \n",
            "                                 (None, 15)]                                                      \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 4144, 15),   1860        ['lstm[0][0]']                   \n",
            "                                 (None, 15),                                                      \n",
            "                                 (None, 15)]                                                      \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 15)     434955      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 4144, 15),   1860        ['lstm_1[0][0]']                 \n",
            "                                 (None, 15),                                                      \n",
            "                                 (None, 15)]                                                      \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 15),   1860        ['embedding_1[0][0]',            \n",
            "                                 (None, 15),                      'lstm_2[0][1]',                 \n",
            "                                 (None, 15)]                      'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " attention (Attention)          (None, 4144, 15)     0           ['lstm_2[0][0]',                 \n",
            "                                                                  'lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, 4144, 30)     0           ['lstm_3[0][0]',                 \n",
            "                                                                  'attention[0][0]']              \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, 4144, 28997)  898907     ['concat_layer[0][0]']           \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,776,257\n",
            "Trainable params: 1,776,257\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 4144)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 4144, 15)     434955      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 4144, 15),   1860        ['embedding[0][0]']              \n",
            "                                 (None, 15),                                                      \n",
            "                                 (None, 15)]                                                      \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 4144, 15),   1860        ['lstm[0][0]']                   \n",
            "                                 (None, 15),                                                      \n",
            "                                 (None, 15)]                                                      \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 15)     434955      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 4144, 15),   1860        ['lstm_1[0][0]']                 \n",
            "                                 (None, 15),                                                      \n",
            "                                 (None, 15)]                                                      \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 15),   1860        ['embedding_1[0][0]',            \n",
            "                                 (None, 15),                      'lstm_2[0][1]',                 \n",
            "                                 (None, 15)]                      'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " attention (Attention)          (None, 4144, 15)     0           ['lstm_2[0][0]',                 \n",
            "                                                                  'lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, 4144, 30)     0           ['lstm_3[0][0]',                 \n",
            "                                                                  'attention[0][0]']              \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, 4144, 28997)  898907     ['concat_layer[0][0]']           \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,776,257\n",
            "Trainable params: 1,776,257\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
      ],
      "metadata": {
        "id": "F2lcAiV2YfTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
      ],
      "metadata": {
        "id": "pq4RsCWIZGqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit([x_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:] ,epochs=15,callbacks=[es],batch_size=20, validation_data=([x_test,y_test[:,:-1]], y_test.reshape(y_test.shape[0],y_test.shape[1], 1)[:,1:]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "TjIWRHICf7FA",
        "outputId": "1aac30be-2765-4efa-a965-30d1474190e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-731042288ace>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 3313, in concatenate\n        return tf.concat([to_dense(x) for x in tensors], axis)\n\n    ValueError: Exception encountered when calling layer \"concat_layer\" (type Concatenate).\n    \n    Dimension 1 in both shapes must be equal, but are 41 and 4144. Shapes are [20,41] and [20,4144]. for '{{node model_1/concat_layer/concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](model_1/lstm_3/PartitionedCall:1, model_1/attention/MatMul_1, model_1/concat_layer/concat/axis)' with input shapes: [20,41,15], [20,4144,15], [] and with computed input tensors: input[2] = <2>.\n    \n    Call arguments received by layer \"concat_layer\" (type Concatenate):\n       inputs=['tf.Tensor(shape=(20, 41, 15), dtype=float32)', 'tf.Tensor(shape=(20, 4144, 15), dtype=float32)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "\n",
        "        if(sampled_token!='end'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "            # Exit condition: either hit max length or find stop word.\n",
        "            if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
        "                stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "ID_Gu346b8WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
        "        newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "metadata": {
        "id": "sKc6bRv1ceGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(x_val)):\n",
        "  print(\"Review:\",seq2text(x_val[i]))\n",
        "  print(\"Original summary:\",seq2summary(y_val[i]))\n",
        "  print(\"Predicted summary:\",decode_sequence(x_val[i].reshape(1,max_len_text)))\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "YEb77x9JclLy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}